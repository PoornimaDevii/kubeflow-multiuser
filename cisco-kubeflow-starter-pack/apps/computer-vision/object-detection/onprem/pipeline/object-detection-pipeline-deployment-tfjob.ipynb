{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection Pipeline on UCS using Darknet & YOLO\n",
    "\n",
    "This notebook focuses on implementing object detection as a Kubeflow pipeline on Cisco UCS by using Darknet which is a open-source neural network framework, YOLO (You Only Look Once) which is a real-time object detection system.\n",
    "\n",
    "The training is done as a TFJob for better efficiency of training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clone Cisco Kubeflow starter pack repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'cisco-kubeflow-starter-pack'...\n",
      "remote: Enumerating objects: 218, done.\u001b[K\n",
      "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
      "remote: Compressing objects: 100% (117/117), done.\u001b[K\n",
      "remote: Total 6246 (delta 93), reused 183 (delta 64), pack-reused 6028\u001b[K\n",
      "Receiving objects: 100% (6246/6246), 42.37 MiB | 49.35 MiB/s, done.\n",
      "Resolving deltas: 100% (2474/2474), done.\n"
     ]
    }
   ],
   "source": [
    "BRANCH_NAME=\"dev\" #Provide git branch \"master\" or \"dev\"\n",
    "! git clone -b $BRANCH_NAME https://github.com/CiscoAI/cisco-kubeflow-starter-pack.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pip\n",
      "  Downloading pip-20.2.4-py2.py3-none-any.whl (1.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.5 MB 35.3 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.6 are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed pip-20.2.4\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.2.4 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Collecting kfp\n",
      "  Using cached kfp-1.1.1.tar.gz (162 kB)\n",
      "Collecting pillow\n",
      "  Using cached Pillow-8.0.1-cp36-cp36m-manylinux1_x86_64.whl (2.2 MB)\n",
      "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from kfp) (5.3)\n",
      "Requirement already satisfied: google-cloud-storage>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.25.0)\n",
      "Requirement already satisfied: kubernetes<12.0.0,>=8.0.0 in /usr/local/lib/python3.6/dist-packages (from kfp) (10.0.1)\n",
      "Requirement already satisfied: google-auth>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (1.11.0)\n",
      "Collecting requests_toolbelt>=0.8.0\n",
      "  Using cached requests_toolbelt-0.9.1-py2.py3-none-any.whl (54 kB)\n",
      "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.6/dist-packages (from kfp) (1.2.2)\n",
      "Collecting kfp-server-api<2.0.0,>=0.2.5\n",
      "  Using cached kfp-server-api-1.0.4.tar.gz (51 kB)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from kfp) (3.2.0)\n",
      "Collecting tabulate\n",
      "  Using cached tabulate-0.8.7-py3-none-any.whl (24 kB)\n",
      "Collecting click\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Collecting Deprecated\n",
      "  Using cached Deprecated-1.2.10-py2.py3-none-any.whl (8.7 kB)\n",
      "Collecting strip-hints\n",
      "  Using cached strip-hints-0.1.9.tar.gz (30 kB)\n",
      "Collecting docstring-parser>=0.7.3\n",
      "  Using cached docstring_parser-0.7.3.tar.gz (13 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting kfp-pipeline-spec<0.2.0,>=0.1.0\n",
      "  Downloading kfp_pipeline_spec-0.1.2-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: google-resumable-media<0.6dev,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (0.5.0)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-storage>=1.13.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.22.0)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.25.8)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.3.0)\n",
      "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2019.11.28)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (45.1.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/lib/python3/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (1.11.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (0.57.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from kubernetes<12.0.0,>=8.0.0->kfp) (2.8.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0.0)\n",
      "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (4.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.6.1->kfp) (0.2.8)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (0.15.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (19.3.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonschema>=3.0.1->kfp) (1.4.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from Deprecated->kfp) (1.11.2)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from strip-hints->kfp) (0.30.0)\n",
      "Requirement already satisfied: google-api-core<2.0.0dev,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.16.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/lib/python3/dist-packages (from requests->kubernetes<12.0.0,>=8.0.0->kfp) (2.6)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib->kubernetes<12.0.0,>=8.0.0->kfp) (3.1.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonschema>=3.0.1->kfp) (2.1.0)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (2019.3)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (3.11.2)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.16.0->google-cloud-core<2.0dev,>=1.2.0->google-cloud-storage>=1.13.0->kfp) (1.51.0)\n",
      "Building wheels for collected packages: kfp, kfp-server-api, strip-hints, docstring-parser\n",
      "  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.1.1-py3-none-any.whl size=222518 sha256=9b08d126c79f6b71835ea5f70c724a65ec7808e393b5a5b687aecdb375392f80\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/88/9f/b1/149db749eeb26a01ddc590b68d2b9c27a9c7eedb799f47d9f1\n",
      "  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.0.4-py3-none-any.whl size=105034 sha256=0585a47fbc6f9f09171d326e22a85b3449aa281db233202aa66ff51b6d231c9e\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/0f/50/2d/28c9ae498b2e5ff5bf5a9765bca3dcd08ab4a79333670de6cb\n",
      "  Building wheel for strip-hints (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for strip-hints: filename=strip_hints-0.1.9-py2.py3-none-any.whl size=24671 sha256=be8430c20b24352ca09462396f47042f887435afdb1ec4ed544c30143c643c9c\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/21/6d/fa/7ed7c0560e1ef39ebabd5cc0241e7fca711660bae1ad752e2b\n",
      "  Building wheel for docstring-parser (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docstring-parser: filename=docstring_parser-0.7.3-py3-none-any.whl size=19230 sha256=30e4a8c8b5dfc4c1f8173fa4ad8510da878c3026b373d58012bb77ec920ab237\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/32/63/02/bb6eebc5261f10a6de3dcf26336a7b2b8b8dc8cacb6c00f75f\n",
      "Successfully built kfp kfp-server-api strip-hints docstring-parser\n",
      "Installing collected packages: requests-toolbelt, kfp-server-api, tabulate, click, Deprecated, strip-hints, docstring-parser, kfp-pipeline-spec, kfp, pillow\n",
      "\u001b[33m  WARNING: The script tabulate is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m  WARNING: The script strip-hints is installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "\u001b[33m  WARNING: The scripts dsl-compile, dsl-compile-v2 and kfp are installed in '/home/jovyan/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed Deprecated-1.2.10 click-7.1.2 docstring-parser-0.7.3 kfp-1.1.1 kfp-pipeline-spec-0.1.2 kfp-server-api-1.0.4 pillow-8.0.1 requests-toolbelt-0.9.1 strip-hints-0.1.9 tabulate-0.8.7\n"
     ]
    }
   ],
   "source": [
    "#!python3 -m pip install --upgrade pip\n",
    "!pip install kfp pillow --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restart kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import yaml\n",
    "import calendar\n",
    "import requests\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "#Kubeflow\n",
    "import kfp\n",
    "from kfp.aws import use_aws_secret\n",
    "import kfp.compiler as compiler\n",
    "\n",
    "#Kubernetes\n",
    "from kubernetes import client\n",
    "\n",
    "#Tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pipeline components\n",
    "\n",
    "Declare the paths of respective YAML configuration files of each of the pipeline components, in order to load each component into a variable for pipeline execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path='cisco-kubeflow-starter-pack/apps/computer-vision/object-detection/onprem/pipeline/components/v2/'\n",
    "component_root_dwn= path+'download/'\n",
    "component_root_train= path+'tfjob/'\n",
    "component_root_convert= path+'tflite-conversion/'\n",
    "component_root_inference= path+'inference/'\n",
    "\n",
    "download_op = kfp.components.load_component_from_file(os.path.join(component_root_dwn, 'component.yaml'))\n",
    "tfjob_create_op = kfp.components.load_component_from_file(os.path.join(component_root_train, 'component.yaml'))\n",
    "tflite_convert_op = kfp.components.load_component_from_file(os.path.join(component_root_convert, 'component.yaml'))\n",
    "inference_op = kfp.components.load_component_from_file(os.path.join(component_root_inference, 'component.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define volume claim & volume mount for storage during pipeline execution\n",
    "\n",
    "Persistent volume claim & volume mount is created for the purpose of storing entities such as Dataset, model files, etc, and to share the stored resources between the various components of the pipeline during it's execution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs_pvc = client.V1PersistentVolumeClaimVolumeSource(claim_name='nfs')\n",
    "nfs_volume = client.V1Volume(name='nfs', persistent_volume_claim=nfs_pvc)\n",
    "nfs_volume_mount = client.V1VolumeMount(mount_path='/mnt/', name='nfs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define pipeline function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_detection_pipeline(\n",
    "    s3_path=\"s3://darknet-datasets\",        # AWS S3 bucket URL. Ex: s3://<bucket-name>/ \n",
    "    namespace='kubeflow',               # Namespace on which trained model is to be deployed for prediction\n",
    "    timestamp=\"\",                       # Current timestamp\n",
    "    cfg_data=\"voc.data\",                # Config file containing file name specifications of train, test and validate datasets\n",
    "    weights=\"yolov3-voc_50000.weights\", # Weights which are already pre-trained upto 50000 iterations is used. Therefore,  \n",
    "                                        # training happens from 50000 iterations upto a limit of max_batches (say 50200) specified \n",
    "                                        # in cfg_file. \n",
    "   \n",
    "    classes_file=\"voc.names\",           # File containing the names of object classes (such as person, bus, car,etc)\n",
    "    push_to_s3=\"True\"                   # Pushes the converted tflite model & trained weights to S3 bucket if set to 'True'\n",
    "                                        # Proceeds with testing inference using converted tflite model if set to 'False'\n",
    "):\n",
    "    \n",
    "    # Download component\n",
    "    dwn_task = download_op(s3_path=s3_path,\n",
    "                           cfg_data=cfg_data\n",
    "                          ).apply(use_aws_secret(secret_name='aws-secret', aws_access_key_id_name='AWS_ACCESS_KEY_ID', aws_secret_access_key_name='AWS_SECRET_ACCESS_KEY'))\n",
    "    dwn_task.add_volume(nfs_volume)\n",
    "    dwn_task.add_volume_mount(nfs_volume_mount) \n",
    "    \n",
    "    # TF-job component\n",
    "    \n",
    "    tfjob_create_task = tfjob_create_op(timestamp=timestamp)\n",
    "    tfjob_create_task.add_volume(nfs_volume)\n",
    "    tfjob_create_task.add_volume_mount(nfs_volume_mount)\n",
    "    tfjob_create_task.after(dwn_task)\n",
    "    \n",
    "    # Tflite Conversion component\n",
    "    \n",
    "    tflite_convert_task = tflite_convert_op(s3_path=s3_path,\n",
    "                                            push_to_s3=push_to_s3,\n",
    "                                            classes_file=classes_file\n",
    "                                       ).apply(use_aws_secret(secret_name='aws-secret', aws_access_key_id_name='AWS_ACCESS_KEY_ID', aws_secret_access_key_name='AWS_SECRET_ACCESS_KEY'))\n",
    "    tflite_convert_task.add_volume(nfs_volume)\n",
    "    tflite_convert_task.add_volume_mount(nfs_volume_mount)\n",
    "    tflite_convert_task.after(tfjob_create_task)\n",
    "\n",
    "    \n",
    "    # Inference component\n",
    "    \n",
    "    inference_task = inference_op()\n",
    "    inference_task.add_volume(nfs_volume)\n",
    "    inference_task.add_volume_mount(nfs_volume_mount)\n",
    "    inference_task.after(tflite_convert_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile pipeline function\n",
    "\n",
    "Compile the pipeline function to create a tar ball for the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile pipeline\n",
    "try:\n",
    "    compiler.Compiler().compile(object_detection_pipeline, 'object-detection.tar.gz')\n",
    "except RuntimeError as err:\n",
    "    logging.debug(err)\n",
    "    logging.info(\"Argo workflow failed validation check but it can still be used to run experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/experiments/details/c3aa019c-9bb5-4f88-a64a-33996d77f2e1\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kp_client = kfp.Client()\n",
    "EXPERIMENT_NAME = 'Object Detection'\n",
    "experiment = kp_client.create_experiment(name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize pipeline parameters & run pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"/pipeline/#/runs/details/c195c1dd-7ad7-45ff-861b-bf0f94ef8d25\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Pipeline parameters\n",
    "timestamp = str(calendar.timegm(time.gmtime()))\n",
    "\n",
    "# Execute pipeline\n",
    "run = kp_client.run_pipeline(experiment.id, 'object-detection', 'object-detection.tar.gz', \n",
    "                          params={\"timestamp\": timestamp})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
